{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import baggianalysis as ba\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial import distance_matrix\n",
    "from icp import icp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arms = 30\n",
    "N_per_arm = 30\n",
    "# we want to retain the central bead\n",
    "ids = [0, ]\n",
    "# and the tips of the arms\n",
    "ids += [a * N_per_arm + N_per_arm for a in range(arms)]\n",
    "myfilter = ba.FilterByFunction(lambda p: p.index in ids)\n",
    "\n",
    "parser = ba.GenericOxDNAParser(\"ba_topology.dat\")\n",
    "trajectory = ba.FullTrajectory(parser)\n",
    "trajectory.add_filter(myfilter)\n",
    "trajectory.initialise_from_trajectory_file(\"trajectory.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distances: [12.23464495 12.32709907 12.30352984 12.05665088 12.1298742  12.31562993\n",
      " 12.26249684 12.1334117  12.28552248 11.98653209 12.26499654 12.28407311\n",
      " 12.28362966 12.10006092 12.34939585 12.17344873 12.29649194 12.24668078\n",
      " 12.28852312 11.91040085 12.17655181 12.09880717 12.11550542 12.29112547\n",
      " 12.17697587 12.08147486 11.93853086 12.38213588 12.25555659 12.52767926]\n",
      "Average distance: 12.209247888907521\n"
     ]
    }
   ],
   "source": [
    "# compute the average distance between the tips and the centre\n",
    "trajectory.reset()\n",
    "system = trajectory.next_frame()\n",
    "dist_avg_per_tip = np.zeros(arms)\n",
    "n_confs = 0\n",
    "while system != None:\n",
    "    n_confs += 1\n",
    "    centre = system.particle_by_id(0).position\n",
    "    for i, p_idx in enumerate(ids[1:]):\n",
    "        distance = system.particle_by_id(p_idx).position - centre\n",
    "        dist_avg_per_tip[i] += np.sqrt(np.dot(distance, distance))\n",
    "\n",
    "    system = trajectory.next_frame()\n",
    "\n",
    "dist_avg_per_tip /= n_confs\n",
    "dist_avg = np.mean(dist_avg_per_tip)\n",
    "print(\"Average distances:\", dist_avg_per_tip)\n",
    "print(\"Average distance:\", dist_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory.reset()\n",
    "system = trajectory.next_frame()\n",
    "n_confs = 0\n",
    "base_positions = None\n",
    "while system != None:\n",
    "    n_confs += 1\n",
    "    \n",
    "    positions = []\n",
    "    for p in system.particles():\n",
    "        if p.index == 0:\n",
    "            centre = p.position\n",
    "        else:\n",
    "            positions.append(p.position)\n",
    "    positions -= centre\n",
    "    \n",
    "    if base_positions is None:\n",
    "        base_positions = np.copy(positions)\n",
    "        dest = np.copy(base_positions)\n",
    "    else:\n",
    "        T, distances, iterations = icp(positions, base_positions)\n",
    "\n",
    "        # make C a homogeneous representation of src\n",
    "        C = np.ones((arms, 4))\n",
    "        C[:,0:3] = np.copy(positions)\n",
    "        # transform C according to the change of coordinates obtained with the icp procedure\n",
    "        C = np.dot(T, C.T).T\n",
    "        # obtain the new coordinates\n",
    "        positions_corrected = C[:,:3]\n",
    "        \n",
    "        # compute the distance matrix\n",
    "        graph_weights = distance_matrix(base_positions, positions_corrected)\n",
    "        # perform the linear assignment\n",
    "        row_ind, col_ind = linear_sum_assignment(graph_weights)\n",
    "        # reorder the array according to the result of the linear assignment\n",
    "        positions_corrected_reordered = positions_corrected[col_ind,:]\n",
    "        \n",
    "        dest += positions_corrected_reordered\n",
    "    \n",
    "    system = trajectory.next_frame()\n",
    "\n",
    "dest /= n_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_distance_matrix = distance_matrix(dest, dest)\n",
    "cut_off = dest_distance_matrix.max()\n",
    "dest_distance_matrix_norm = dest_distance_matrix / cut_off\n",
    "\n",
    "first_piece = dest_distance_matrix_norm < 0.5\n",
    "second_piece = (dest_distance_matrix_norm >= 0.5) & (dest_distance_matrix_norm < 1.0)\n",
    "third_piece = dest_distance_matrix_norm >= 1.0\n",
    "\n",
    "weight_matrix = np.piecewise(\n",
    "    dest_distance_matrix_norm, \n",
    "    [first_piece, second_piece, third_piece],\n",
    "    [lambda r: 1 - 6*r**2 + 6*r**3, lambda r: 2 - 6*r + 6*r**2 - 2*r**3, 0.]\n",
    ")\n",
    "# see https://stackoverflow.com/a/54637261/5140209\n",
    "weight_matrix = np.broadcast_to(weight_matrix[:,:,np.newaxis,np.newaxis], (arms, arms, 3, 3))\n",
    "\n",
    "# now we compute D_inv for each reference point\n",
    "dest_diff_matrix = dest[:, np.newaxis, :] - dest\n",
    "# first we perform an outer product on the last axis\n",
    "D = dest_diff_matrix[:,:,:,np.newaxis] * dest_diff_matrix[:,:,np.newaxis,:] * weight_matrix\n",
    "# then we sum over all the points (i.e. on the second axis)\n",
    "D = np.sum(D, axis=1)\n",
    "# and invert the matrices\n",
    "D_inv = np.linalg.inv(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_F(system):\n",
    "    src = []\n",
    "    for p in system.particles():\n",
    "        if p.index == 0:\n",
    "            centre = p.position\n",
    "        else:\n",
    "            src.append(p.position)\n",
    "    src -= centre\n",
    "    \n",
    "    T, distances, iterations = icp(src, dest)\n",
    "\n",
    "    # make C a homogeneous representation of src\n",
    "    C = np.ones((arms, 4))\n",
    "    C[:,0:3] = np.copy(src)\n",
    "    # transform C according to the change of coordinates obtained with the icp procedure\n",
    "    C = np.dot(T, C.T).T\n",
    "    # obtain the new coordinates\n",
    "    src_corrected = C[:,:3]\n",
    "    \n",
    "    # compute the distance matrix\n",
    "    graph_weights = distance_matrix(dest, src_corrected)\n",
    "    # perform the linear assignment\n",
    "    row_ind, col_ind = linear_sum_assignment(graph_weights)\n",
    "    # reorder the array according to the result of the linear assignment\n",
    "    src_corrected_reordered = src_corrected[col_ind,:]\n",
    "    \n",
    "    # compute A for each point\n",
    "    src_diff_matrix = src_corrected_reordered[:, np.newaxis, :] - src_corrected_reordered\n",
    "    A = src_diff_matrix[:,:,:,np.newaxis] * dest_diff_matrix[:,:,np.newaxis,:] * weight_matrix\n",
    "    # then we sum over all the points (i.e. along the second axis)\n",
    "    A = np.sum(A, axis=1)\n",
    "\n",
    "    F = A @ D_inv\n",
    "\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysed 100 confs\n",
      "Analysed 200 confs\n",
      "Analysed 300 confs\n",
      "Analysed 400 confs\n",
      "Analysed 500 confs\n"
     ]
    }
   ],
   "source": [
    "trajectory.reset()\n",
    "system = trajectory.next_frame()\n",
    "confs = 0\n",
    "J_tot = []\n",
    "I_tot = []\n",
    "J_avg = []\n",
    "I_avg = []\n",
    "J_from_F_avg = []\n",
    "I_from_F_avg = []\n",
    "while system != None:\n",
    "    confs += 1\n",
    "    if confs % 100 == 0:\n",
    "        print(\"Analysed %s confs\" % confs)\n",
    "\n",
    "    # and now we can compute the Cauchy-Green strain tensor\n",
    "    F = compute_F(system)\n",
    "    F_T = np.transpose(F, axes=(0,2,1))\n",
    "    C = np.matmul(F_T, F)\n",
    "\n",
    "    # from the invariants of C we obtain J and I\n",
    "    J = np.sqrt(np.linalg.det(C))\n",
    "    I = np.trace(C, axis1=1, axis2=2) / J**(2./3.)\n",
    "    \n",
    "    J_tot += list(J)\n",
    "    I_tot += list(I)\n",
    "        \n",
    "    J_avg.append(np.average(J))\n",
    "    I_avg.append(np.average(I * J**(2./3.)) / J_avg[-1]**(2./3.))\n",
    "    #I_avg.append(np.average(I))\n",
    "    \n",
    "    F_avg = np.average(F, axis=0)\n",
    "    C_avg = F_avg.T @ F_avg\n",
    "    J_from_F_avg.append(np.sqrt(np.linalg.det(C_avg)))\n",
    "    I_from_F_avg.append(np.trace(C_avg) / J_from_F_avg[-1]**(2./3.))\n",
    "\n",
    "    system = trajectory.next_frame()\n",
    "\n",
    "np.savetxt(\"J.dat\", J_tot)\n",
    "np.savetxt(\"I.dat\", I_tot)\n",
    "\n",
    "np.savetxt(\"J_avg.dat\", J_avg)\n",
    "np.savetxt(\"I_avg.dat\", I_avg)\n",
    "\n",
    "np.savetxt(\"J_from_F_avg.dat\", J_from_F_avg)\n",
    "np.savetxt(\"I_from_F_avg.dat\", I_from_F_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pmf(x, remove_last=False):\n",
    "    hist, bins = np.histogram(x, bins='auto', density=True)\n",
    "    bins = bins[:-1] + (bins[1] - bins[0]) / 2.\n",
    "    result = np.column_stack((bins, hist))\n",
    "    # get rid of the last points\n",
    "    if remove_last != False:\n",
    "        if len(bins) < 2 * remove_last:\n",
    "            remove_last = len(bins) / 5\n",
    "        result = result[result[:,1] > 0][:-remove_last]\n",
    "    else:\n",
    "        result = result[result[:,1] > 0]\n",
    "    result[:,1] = -np.log(result[:,1])\n",
    "\n",
    "    return result\n",
    "\n",
    "def fit_J(x, m, D0, b):\n",
    "    return m * (x - D0)**2. + b\n",
    "\n",
    "def fit_I(x, m, b):\n",
    "    return m * x + b\n",
    "\n",
    "pmf_J = make_pmf(J_tot)\n",
    "pmf_I = make_pmf(I_tot, 50)\n",
    "\n",
    "np.savetxt(\"J_pmf.dat\", pmf_J)\n",
    "np.savetxt(\"I_pmf.dat\", pmf_I)\n",
    "\n",
    "pmf_J_avg = make_pmf(J_avg)\n",
    "pmf_I_avg = make_pmf(I_avg)\n",
    "\n",
    "np.savetxt(\"J_avg_pmf.dat\", pmf_J_avg)\n",
    "np.savetxt(\"I_avg_pmf.dat\", pmf_I_avg)\n",
    "\n",
    "pmf_J_from_F_avg = make_pmf(J_from_F_avg)\n",
    "pmf_I_from_F_avg = make_pmf(I_from_F_avg)\n",
    "\n",
    "np.savetxt(\"J_from_F_avg_pmf.dat\", pmf_J_from_F_avg)\n",
    "np.savetxt(\"I_from_F_avg_pmf.dat\", pmf_I_from_F_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
